---
output: html_document
---
--- title: "Section2_Lab03_SwaminathanV_PalitS" output: html_document ---

## Abstract

Big box retailers such as Walmart need to have accurate models of purchasing
patterns at their various stores. Overestimating consumer demand could lead to
losses due to excess inventory.

On the other hand, underestimating it could result in lower customer service
level and lost sales.

Our dataset contains historical sales data for 45 Walmart stores located in
different regions. Each store contains a number of departments.

For the purpose of this lab, we are analyzing a randomly chosen store 4
and department 12 ( based on a random number generator)


- Is there a relationship between temperature and sales?

- Is there a relationship between CPI and sales?

- Is there a relationship between fuel price and sales?

- Is there a relationship between unemployment and sales?



Finally, we are going to forecast sales for this store which will help them maximize sales and optimize inventory.




```{r libs, include=FALSE} 
library(zoo) 
library(tseries) 
library(forecast) 
library(vars) 
library(urca) 
library(knitr)
rm(list = ls()) 
```





##Loading the source datasets and the required libraries 
```{r setup,include=TRUE}
train<-read.csv('/Users/vyas/Dropbox/Berkeley MIDS/Advanced Regression/W271 Lab 3/train.csv')
features<-read.csv('/Users/vyas/Dropbox/Berkeley MIDS/Advanced Regression/W271 Lab 3/features.csv')
train <- train[train['Dept']==12,] 
train<-train[,c(1,2,3,4)] 
```

## Function to perform EDA on time series 
```{r edats} 
tseda<-function(timeseries,xlabel,ylabel,mainlabel){ 
  plot(timeseries,xlab=xlabel,ylab=ylabel,main=mainlabel) 
  #par(mfrow=c(1,2)) 
  Acf(timeseries,main = paste(mainlabel,' ACF')) 
  Pacf(timeseries,main =
  paste(mainlabel,' Pacf')) 
  adf.test(timeseries) 
  }

``` 


## Function to perform out of sample tests on forecasts using RMSE 
```{r rmse} 
rmse<-function(timeseries1,timeseries2){ 
return(sqrt(mean((timeseries1-timeseries2)^2))) }

```



##Merging and filtering the data 
```{r mergefilter} 
input<-merge(train,features,by  =c("Store","Date")) 
input<-input[,c(1,2,3,4,5,6,12,13)] 
input<-input[(input["Store"]==4)|(input["Store"]==14)|(input["Store"]==15),] 
store4_data<-input[input["Store"]==4,]
```




##Describe the time series in the dataset

```{r} 
str(store4_data) 
summary(store4_data)
```

Based on an analysis of the structure of the data, it doesn't appear as though there are missing values in the data set.

## Examine the various series for stationarity 
* The ACF and PACF plots for all the time series show the classic signature for an AR model of root 1. The ACF drops down slowly while the PACF drops suddenly at lag 1. This series' will need to be differenced at least once to get to stationarity

###Time Series 1: Sales 
```{r stationarity ss} 
store4_sales.ts<-ts(store4_data$Weekly_Sales,start =c(2010,5),freq=52) 
tseda(store4_sales.ts,"Year","Sales at Store 4","Store 4
Sales by Year") 
```



###Time Series 2: Temperature

```{r stationarity temp} 
store4_temp.ts<-ts(store4_data$Temperature,start =c(2010,5),freq=52) 
tseda(store4_temp.ts,"Year","Temperature","Temperature by
Year") 
```



###Time Series 3: Unemployment Rate

```{r stationarity ue} 
store4_ue.ts<-ts(store4_data$Unemployment,start = c(2010,5),freq=52) 
tseda(store4_ue.ts,"Year","Unemployment Rate","Unemployment Rate by Year") 
```



###Time Series 4: Fuel Price

```{r stationarity fp} 
store4_fp.ts<-ts(store4_data$Fuel_Price,start = c(2010,5),freq=52) 
tseda(store4_fp.ts,"Year","Fuel Price","Fuel Price by Year") 
```

###Time Series 5: CPI

```{r stationarity cpi} 
store4_cpi.ts<-ts(store4_data$CPI,start =c(2010,5),freq=52) 
tseda(store4_sales.ts,"Year","CPI","CPI by Year") 
```





##Converting non-stationary time series to stationary series by differencing 
###Time Series 1: Sales 
```{r diff ss} 
store4_sales.d.ts<-diff(store4_sales.ts,differences=1,lag=1) 
tseda(store4_sales.d.ts,"Year","Sales at Store 4","Store 4 Sales by Year (Differenced)") 
```

By differencing the "sales" time series once, we're able to see via the plot and the ADF test that the differenced series is stationary. This means that the "sales" series was integrated with order 1 (I(1)). The differenced series has been stored in a new variable (store4_sales.d.ts)


###Time Series 2: Temperature

```{r diff temp} 
store4_temp.d.ts<-diff(store4_temp.ts,differences=1,lag=1)
tseda(store4_temp.d.ts,"Year","Temperature","Temperature by Year (Differenced)")

```

Differencing the "temperature" time series once has created a time series that "looks" stationary with the first order difference. However, the ADT test says that the null hypothesis that the process is still unit root can't be rejected, and this can be seen in the damping of the ACF and the pacfs which are slightly significant. However, we want to avoid over-differencing and for our purposes here, we're dont think our analysis would be impacted if we assumed that temperature is an I(1) series.

###Time Series 3: Unemployment 
```{r diff ue} 
store4_ue.d.ts<- diff(store4_ue.ts,differences=1,lag=1)
tseda(store4_ue.d.ts,"Year","Unemployment Rate","Unemployment Rate by Year (Differenced)") 
```
Analyzing the unemployment variable after the first order difference,  the ADF function returns a p value of 0.01 rejecting the null hypothesis of unit root stationarity

###Time Series 4: Fuel Price 
```{r diff fp} 
store4_fp.d.ts<-diff(store4_fp.ts,differences=1,lag=1)
tseda(store4_fp.d.ts,"Year","Fuel Price","Fuel Price by Year (Differenced)") 
```
The first order difference of the "fuel price" time series satisfies the conditions of stationarity from an analysis of the acf,pacf and the ADF test.

###Time Series 5: CPI 
```{r diff cpi} 
store4_cpi.d.ts<-diff(store4_cpi.ts,differences=1,lag=1) 
tseda(store4_cpi.d.ts,"Year","CPI","CPI by Year (Differenced)") 
store4_cpi.d.ts<-diff(store4_cpi.d.ts,differences=1,lag=1) 
tseda(store4_cpi.d.ts,"Year","CPI","CPI by Year (Second Order Differenced)") 
```
After differencing once, the store4_cpi.ts time series continues to show strong evidence that it is a unit root series (through the ACF, PACF and ADF test). We have differenced the series once more to make it stationary.


##Analyze cross-correlations 
```{r cc} 
Ccf(store4_sales.d.ts,store4_temp.d.ts) 
Ccf(store4_sales.d.ts,store4_cpi.d.ts) 
Ccf(store4_sales.d.ts,store4_ue.d.ts) 
Ccf(store4_sales.d.ts,store4_fp.d.ts) 
```
Cross correlations are evaluated against differenced time series below.

* Based on the cross-correlation betwen temperature and sales, it appears as though there may not be a significant relationship between these two time series after the first 2-3 lags, although the first lag seems to be somewhat strongly correlated

*CPI and Sales do not seem to have any cross correlations of any importance at all

*Unemployment and Sales seem to have some small cross-correlations of interest although many seem coincidental (for example the 0.2 cross correlation at around lag 60)

*Fuel price and sales do not seem to have any cross correlations of any importance at all

We will model all these relationships during estimation, but based on these cross-correlations, the relationship between Sales and Temperature seems to be the most important, while unemployment may be of secondary importance.

##Analyze cointegrations 
```{r}

po.test(cbind(store4_temp.ts,store4_sales.ts))

po.test(cbind(diff(store4_cpi.ts),store4_sales.ts))

po.test(cbind(store4_ue.ts,store4_sales.ts))

po.test(cbind(store4_fp.ts,store4_sales.ts))


```

* Based on this analysis, it appears as if sales are cointegrated with temperature (p-value of 0.03). In order to correctly model cointegrated series, we would need to use VECM (Vector Error Correcton Models) which have not been covered in this course so far. For the purpose of this lab, we will proceed by building standard VAR models after making a note of this detail.

#Estimation 

##Break data into in-sample and out of Sample Data Sets

We are breaking the time-series' up into in-sample and out-of-sample components. The in-sample set has 129 rows while the out of sample data contains 13 rows (10%).

```{r break data into in-sample and out-of-sample data sets} 
istartindex=2 
iendindex=130
ostartindex=iendindex+1 
oendindex=dim(as.matrix(store4_sales.d.ts))[c(1)]

modelinput = cbind(store4_sales.d.ts,store4_temp.d.ts,store4_ue.d.ts,store4_fp.d.ts,store4_cpi.d.ts)[istartindex:iendindex,]
modeloos=cbind(store4_sales.d.ts,store4_temp.d.ts,store4_ue.d.ts,store4_fp.d.ts,store4_cpi.d.ts)[ostartindex:oendindex,]
```


##Estimate VAR model

###This function will be used to calculate out of sample RSME's for our models
```{r forecastfunc} 
oosrmse<-function(model){
  p<-predict(model,n.ahead=oendindex-iendindex+1)
  rmse(p$fcst$store4_sales.d.ts[,c(1)],modeloos[,c(1)])
}
```



###AR Model with Sales alone
```{r estimate ar1} 

modelar<-ar(modelinput[,c(1)],method = 'ols',dmean=T,intercept=F) 
summary(modelar) 
modelar$ar
modelar$aic
```

For a simple AR model, the fit only considers the first three lag terms. This gives us a hint which is further validated by the Acf and Pacf of sales that higher order lag terms may not be significant when it pertains to the sales variable.


###Model1: Sales+Temperature

```{r estimate var1} 
VARselect(modelinput[,c(1,2)], lag.max = 6) 
model1<-VAR(modelinput[,c(1,2)],p=1,ic="AIC")
summary(model1) 
oosrmse(model1)
```
After adding temperature, VARSelect recommends an order of 5 based on AIC. However, there isn't a significant difference between VAR(1) and VAR(5) in terms of AIC and so in the interest of parsimony, we are choosing a VAR(1) model

###Model2: Sales+Temperature+Unemployment

```{r estimate var2} 
VARselect(modelinput[,c(1,2,3)], lag.max = 6) 
model2<-VAR(modelinput[,c(1,2,3)],p=1,ic="AIC")
summary(model2) 
oosrmse(model2)
```
After adding Unemployment, VARSelect recommends an order of 6 based on AIC. However, there isn't a significant difference between VAR(1) and VAR(6) in terms of AIC and so in the interest of parsimony, we are choosing a VAR(1) model

###Model3: Sales+Temperature+Unemployment+FuelPrice

```{r estimate var3} 
VARselect(modelinput[,c(1,2,3,4)], lag.max = 6) 
model3<-VAR(modelinput[,c(1,2,3,4)],p=1,ic="AIC")
summary(model3) 
oosrmse(model3)
```
After adding Fuel Price, VARSelect continues to recommend an order of 1. We use this order to build the model.

###Model4: Sales+Temperature+Unemployment+FuelPrice+CPI

```{r estimate var4} 
VARselect(modelinput[,c(1,2,3,4,5)], lag.max = 6) 
model4<-VAR(modelinput[,c(1,2,3,4,5)],p=1,ic="AIC")
summary(model4) 
oosrmse(model4)
```
After adding CPI, VARSelect continues to recommend an order of 1. We use this order to build the model.



##Model Selection


|  Model       |Time Series' Included                         | Adjusted R2 |     RMSE     |
|-------------:|---------------------------------------------:|------------:|-------------:|
|  Model1      | Sales+Temperature                            |   0.18      |  1055.817   |  
|  Model2      | Sales+Temperature+Unemployment               |   0.20      |  1058.585    |   
|  Model3      | Sales+Temperature+Unemployment+FuelPrice     |   0.19      |  1059.666    | 
|  Model4      | Sales+Temperature+Unemployment+FuelPrice+CPI |   0.19      |  1059.279    |     

Based on the R2 values and the RMSE of the out-of-sample projections vs the actual values, we have chosen Model2 as our final VAR model and the Sales, Temperature and Unemployment as the variables to include in the model. 

###Final VAR model



```{r estimate var5} 
finalmodel<-VAR(modelinput[,c(1,2,3)],p=1,ic="AIC")
summary(finalmodel) 
oosrmse(finalmodel)
```

Key insights from this model are
* The first lag of sales and temperature seem to be significant. This makes sense since these two variables are cointegrated
* The first lag of unemployment seems to be slightly significant

#Diagnostics

```{r diagnostics} 
par(mar = rep(2, 4))

plot.ts(resid(finalmodel)[,c(1)],main="Plot of Residuals of Sales Time Series")
Box.test(resid(finalmodel)[,c(1)],type = c("Ljung-Box"))

#Tests for normality
hist(resid(finalmodel)[,c(1)],main = "Histogram of Residuals of Final Model",xlab="")
qqnorm(resid(finalmodel)[,c(1)],main = "QQ Plot of Residuals of Final Model",xlab="")
```


In the plots and tests above, we test the residuals from the chosen model (for sales only)for-

* Independence
* Normality


The residuals appear to be independent and identically distributed (iid). Based on the Ljung-Box test, the null hypothesis that the residuals are iid cannot be rejected.
The histogram of the residuals and the qqplot further validate the normality of the residuals

#Model Performance Evaluation

```{r performance evaluation}
par(mfrow=c(1,1))
 plot.ts(modelinput[,c(1)],col="navy",lty=2,main="Original vs Estimated Series (First Difference)",ylab = "Original and Estimated  Values",xlim = c(0,120),ylim=c(-3000,3000))
 par(new=T)
 plot.ts(fitted(finalmodel)[,c(1)],col="red",xlim = c(0,120),ylim=c(-3000,3000),xlab="",ylab="")

```

```{r performance evaluation2}
par(mfrow=c(1,1))
 plot.ts(cumsum(c(store4_sales.ts[1],modelinput[,c(1)])),col="navy",lty=2,main="Original vs Estimated Series (Integrated)",ylab = "Original and Estimated  Values",xlim = c(0,120),ylim=c(4000,13000))
 par(new=T)
 plot.ts(cumsum(c(store4_sales.ts[1],fitted(finalmodel)[,c(1)])),col="red",xlim = c(0,120),ylim=c(4000,13000),xlab="",ylab="")

```

Based on the graphs above, we can conclude that the model provides a reasonably good fit to the sales data 

#Hypothesis testing

- Is there a relationship between temperature and sales?

There appears to be a strong relationship between sales and the first lag of temperature. Make a note here however that these two time series are cointegrated.

- Is there a relationship between CPI and sales?

There doesn't appear to be a relationship between these two variables

- Is there a relationship between fuel price and sales?

There doesn't appear to be a relationship between these two variables


- Is there a relationship between unemployment and sales?

There appears to be a relationship sales and the first lag of unemployment


#Forecasting

```{r forecast} 
p<-predict(finalmodel,n.ahead=20)

fc<-cumsum(union(fitted(finalmodel)[,c(1)],p$fcst$store4_sales.d.ts[,c(1)]))
fc<-ts(fc)
plot(fc, main = "Sales Forecast", xlab = "Time",ylab="Sales")
fc[c(143:148)]
```

We forecast that on an average, the store will sell the units projected above in department 12 for the next 5 time weeks.

